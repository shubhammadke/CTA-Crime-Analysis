{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the essential libraries used for the Deep learning and neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the test and train data for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN DATA\n",
    "dataset = pd.read_csv(\"traindata.csv\")\n",
    "#TEST DATA\n",
    "dataset1= pd.read_csv(\"testdata.csv\")\n",
    "\n",
    "\n",
    "dataset=dataset.drop('cta_sites',axis=1)\n",
    "dataset=dataset.drop('incident_date',axis=1)\n",
    "dataset=dataset.drop('incident_time',axis=1)\n",
    "dataset=dataset.drop('incident_category',axis=1)\n",
    "dataset=dataset.drop('hours_after_sunrise',axis=1)\n",
    "dataset=dataset.drop('hours_to_sunset',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset = Operation on Train data \n",
    "\n",
    "\n",
    "Dataset1 = Operation on Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=dataset1.drop('cta_sites',axis=1)\n",
    "dataset1=dataset1.drop('incident_date',axis=1)\n",
    "dataset1=dataset1.drop('incident_time',axis=1)\n",
    "dataset1=dataset1.drop('incident_category',axis=1)\n",
    "dataset1=dataset1.drop('hours_after_sunrise',axis=1)\n",
    "dataset1=dataset1.drop('hours_to_sunset',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating copy of both the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_df=dataset.copy(deep=True)\n",
    "churn_df1=dataset1.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['moonrise'] = label_encoder.fit_transform(data['moonrise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the Best feature method for features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 25)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection on data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = churn_df.iloc[:,0:27]  #independent columns\n",
    "y = churn_df.iloc[:,-1]    #target column i.e incident\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2 , k=10)\n",
    "X=X.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Specs       Score\n",
      "0           site_id  433.348843\n",
      "24         incident  149.000000\n",
      "9        restaurant   52.865659\n",
      "20     weather_code   47.082929\n",
      "16         moonrise   43.410635\n",
      "22       cloudcover   30.536533\n",
      "21         Humidity   11.675018\n",
      "5   incident_time_1   10.913251\n",
      "14           sunset   10.010431\n",
      "7         time_code    9.180694\n"
     ]
    }
   ],
   "source": [
    "print(featureScores.nlargest(10,'Score'))  #print 10 best feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using only these features in our models\n",
    "data=dataset[['site_id','incident','restaurant','cloudcover','moonrise','Humidity','weather_code','time_code','incident_time_1','sunset']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the same atriburte sin the test data as well to check the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using only these features in our models\n",
    "data1=dataset1[['site_id','incident','restaurant','cloudcover','moonrise','Humidity','weather_code','time_code','incident_time_1','sunset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashag\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['moonrise'] = label_encoder.fit_transform(data['moonrise'])\n",
    "data['sunset'] = label_encoder.fit_transform(data['sunset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>incident</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>moonrise</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>time_code</th>\n",
       "      <th>incident_time_1</th>\n",
       "      <th>sunset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>11:45</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>19:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>11:45</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>19:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  incident  restaurant  cloudcover moonrise  Humidity  weather_code  \\\n",
       "0      129         1           9          38    11:45        83             2   \n",
       "1       12         0           0          38    11:45        83             2   \n",
       "\n",
       "   time_code  incident_time_1 sunset  \n",
       "0          5                9  19:17  \n",
       "1          5                9  19:17  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashag\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ashag\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data1['moonrise'] = label_encoder.fit_transform(data1['moonrise'])\n",
    "data1['sunset'] = label_encoder.fit_transform(data1['sunset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>incident</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>moonrise</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>time_code</th>\n",
       "      <th>incident_time_1</th>\n",
       "      <th>sunset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  incident  restaurant  cloudcover  moonrise  Humidity  \\\n",
       "0      129         1           9          38         3        83   \n",
       "1       12         0           0          38         3        83   \n",
       "2       45         0           3          29         3        75   \n",
       "\n",
       "   weather_code  time_code  incident_time_1  sunset  \n",
       "0             2          5                9       0  \n",
       "1             2          5                9       0  \n",
       "2             2          5               11       0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping te output vraible from the test data to check the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.drop('incident',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting particular row to check accuracy for each row\n",
    "###first=data1[:1]\n",
    "##sec=data1[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = list(data.columns.values)\n",
    "properties.remove('incident')\n",
    "X = data[properties]\n",
    "y = data['incident']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Neural Network On the train data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used two layers of 16 nodes each and 1 with output variable \n",
    "Output node we used Signoid function that squeeze values in 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used Rectified Linear Unit as activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(9,)),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "\tkeras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complied the network \n",
    "It used Adam as an Optimizer \n",
    "Loss Function used here is binary_crossentrophy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "361/361 [==============================] - 1s 4ms/sample - loss: 0.1710 - acc: 0.9252\n",
      "Epoch 2/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1154 - acc: 0.9584\n",
      "Epoch 3/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.2322 - acc: 0.9058\n",
      "Epoch 4/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1405 - acc: 0.9418\n",
      "Epoch 5/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1648 - acc: 0.9307\n",
      "Epoch 6/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1475 - acc: 0.9252\n",
      "Epoch 7/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1393 - acc: 0.9335\n",
      "Epoch 8/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1656 - acc: 0.9224\n",
      "Epoch 9/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1467 - acc: 0.9474\n",
      "Epoch 10/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1491 - acc: 0.9391\n",
      "Epoch 11/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1191 - acc: 0.9529\n",
      "Epoch 12/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1739 - acc: 0.9363\n",
      "Epoch 13/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1468 - acc: 0.9391\n",
      "Epoch 14/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1524 - acc: 0.9391\n",
      "Epoch 15/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1500 - acc: 0.9335\n",
      "Epoch 16/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1742 - acc: 0.9307\n",
      "Epoch 17/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1402 - acc: 0.9501\n",
      "Epoch 18/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1302 - acc: 0.9418\n",
      "Epoch 19/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1675 - acc: 0.9335\n",
      "Epoch 20/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1249 - acc: 0.9529\n",
      "Epoch 21/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1508 - acc: 0.9252\n",
      "Epoch 22/50\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.1606 - acc: 0.930 - 1s 3ms/sample - loss: 0.1589 - acc: 0.9307\n",
      "Epoch 23/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1337 - acc: 0.9474\n",
      "Epoch 24/50\n",
      "361/361 [==============================] - 2s 5ms/sample - loss: 0.1198 - acc: 0.9557\n",
      "Epoch 25/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1489 - acc: 0.9418\n",
      "Epoch 26/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1285 - acc: 0.9557\n",
      "Epoch 27/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1271 - acc: 0.9474\n",
      "Epoch 28/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1175 - acc: 0.9529\n",
      "Epoch 29/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1405 - acc: 0.9474\n",
      "Epoch 30/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1519 - acc: 0.9307\n",
      "Epoch 31/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1404 - acc: 0.9446\n",
      "Epoch 32/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1229 - acc: 0.9474\n",
      "Epoch 33/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.0824 - acc: 0.9695\n",
      "Epoch 34/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1560 - acc: 0.9418\n",
      "Epoch 35/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1266 - acc: 0.9557\n",
      "Epoch 36/50\n",
      "361/361 [==============================] - 1s 4ms/sample - loss: 0.1108 - acc: 0.9557\n",
      "Epoch 37/50\n",
      "361/361 [==============================] - 2s 4ms/sample - loss: 0.1067 - acc: 0.9557\n",
      "Epoch 38/50\n",
      "361/361 [==============================] - 2s 6ms/sample - loss: 0.1131 - acc: 0.9557\n",
      "Epoch 39/50\n",
      "361/361 [==============================] - 2s 6ms/sample - loss: 0.1666 - acc: 0.9335\n",
      "Epoch 40/50\n",
      "361/361 [==============================] - 2s 6ms/sample - loss: 0.1157 - acc: 0.9501\n",
      "Epoch 41/50\n",
      "361/361 [==============================] - 1s 3ms/sample - loss: 0.1077 - acc: 0.9668\n",
      "Epoch 42/50\n",
      "361/361 [==============================] - 1s 4ms/sample - loss: 0.1229 - acc: 0.9418\n",
      "Epoch 43/50\n",
      "361/361 [==============================] - 1s 4ms/sample - loss: 0.1622 - acc: 0.9391\n",
      "Epoch 44/50\n",
      "361/361 [==============================] - 2s 5ms/sample - loss: 0.0967 - acc: 0.9668\n",
      "Epoch 45/50\n",
      "361/361 [==============================] - 2s 5ms/sample - loss: 0.0766 - acc: 0.9640\n",
      "Epoch 46/50\n",
      "361/361 [==============================] - 2s 4ms/sample - loss: 0.1084 - acc: 0.9501\n",
      "Epoch 47/50\n",
      "361/361 [==============================] - 1s 4ms/sample - loss: 0.1011 - acc: 0.9584\n",
      "Epoch 48/50\n",
      "361/361 [==============================] - 1s 4ms/sample - loss: 0.0874 - acc: 0.9723\n",
      "Epoch 49/50\n",
      "361/361 [==============================] - 1s 4ms/sample - loss: 0.1230 - acc: 0.9557\n",
      "Epoch 50/50\n",
      "361/361 [==============================] - 1s 4ms/sample - loss: 0.1532 - acc: 0.9307\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit(X_train, y_train, epochs=50, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 0s 95us/sample - loss: 0.0648 - acc: 0.9834\n",
      "Train accuracy: 0.9833795\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 250us/sample - loss: 0.6292 - acc: 0.8258\n",
      "Test accuracy: 0.82580644\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuarcy on test data set that is april data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can increase the accuracy by optimizing epochs, layers  or nodes per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5662741\n"
     ]
    }
   ],
   "source": [
    "a= np.array(data1)\n",
    "print(model.predict(a).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.876106\n",
      "Recall: 0.883929\n",
      "F1 score: 0.880000\n",
      "Accuracy:0.825806\n",
      "[[29 14]\n",
      " [13 99]]\n"
     ]
    }
   ],
   "source": [
    "yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, yhat_classes)\n",
    "recall = recall_score(y_test, yhat_classes)\n",
    "f1 = f1_score(y_test, yhat_classes)\n",
    "matrix = confusion_matrix(y_test, yhat_classes)\n",
    "accuracy= accuracy_score(y_test,yhat_classes)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)\n",
    "print('Accuracy:%f' % accuracy )\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.880000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29 14]\n",
      " [13 99]]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
